## Project Transformers and Machine Translation

In this assignment, I built an English-to-German neural machine translation (NMT) model using Long Short-Term Memory (LSTM) networks with attention for translation from English to German. This assignment includes

- preprocessing training and evaluation data
- implementing an encoder-decoder system with attention
- building the NMT model from scratch using Trax
- generating translations using greedy and Minimum Bayes Risk (MBR) decoding

![attention_overview.png](https://github.com/GlebDubosarskii/Coursera-Natural-Language-Processing-Specialization/blob/main/4.%20Natural%20Language%20Processing%20with%20Attention%20Models/Week%201%20Transformers%20and%20Machine%20Translation/attention_overview.png?raw=true)

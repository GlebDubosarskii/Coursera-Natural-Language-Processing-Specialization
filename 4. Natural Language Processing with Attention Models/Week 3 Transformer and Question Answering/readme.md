## Project Transformer and Question Answering

This project is about implementing the Bidirectional Encoder Representation from Transformer (BERT) and using it for question answering and missing word recovery in a text.

![fulltransformer.png](https://github.com/GlebDubosarskii/Coursera-Natural-Language-Processing-Specialization/blob/main/4.%20Natural%20Language%20Processing%20with%20Attention%20Models/Week%203%20Transformer%20and%20Question%20Answering/fulltransformer.png?raw=true)
